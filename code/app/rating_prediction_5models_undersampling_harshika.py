# -*- coding: utf-8 -*-
"""rating-prediction-5models-undersampling-harshika.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/112nhYGG5lB8pLmrW567qd1jkMsOs8Z4Y
"""

# from google.colab import drive
# drive.mount('/content/drive')
# !pwd

#This notebook contains data balancing using undersampling and comparision of various models for star/rating prediction on Yelp dataset.

import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
from imblearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
from sklearn.svm import LinearSVC
import pickle
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier

import pandas as pd
df =pd.read_csv("/kaggle/input/yelpdataseths/hrdata_modified3.csv")
df.head()

X = df['lemma']
y = df['review_stars']
X_try=X.tolist()
X_try=np.array(X_try)
X_try=X_try.reshape(-1,1)

#undersampling using random undersampler
rus = RandomUnderSampler(random_state=777)
X_RUS, y_RUS = rus.fit_resample(X_try, y)
print(X_RUS.shape)
X_train, x_test, Y_train, y_test = train_test_split(X_RUS,y_RUS,test_size=0.3,random_state=42)

#model 1 linear support vector machine
newpipeline = Pipeline([('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()), 
    ('clf', LinearSVC())])
X_train= X_train.flatten()
x_test= x_test.flatten()

newpipeline.fit(X_train,Y_train) #training the model

#testing accuracy

print('Training set score: ' + str(newpipeline.score(X_train,Y_train)))
print('Test set score: ' + str(newpipeline.score(x_test,y_test)))

#prediction
yhat=newpipeline.predict(x_test)

#plotting matrix
cm=confusion_matrix(y_test, yhat)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

#printing scores
print(metrics.classification_report(y_test, yhat))

#pickle dumping
with open('svc_oversample.pickle', 'wb') as f:
    pickle.dump(newpipeline, f)
with open('svc_oversample.pickle', 'rb') as f:
    loadedpipe = pickle.load(f)
testing=loadedpipe.predict(["This is a good restaurant, but the service is average"])
testing[0]
test_df=pd.DataFrame(
    data={
        'text' : X_RUS.flatten(),
        'stars' : y_RUS
    }
)
test_df.shape
test_df.to_csv('undersampled_dataset.csv', index=False)

#model 2 decision tree classifier
newpipeline2 = Pipeline([('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()), 
    ('clf', DecisionTreeClassifier())])
X_train= X_train.flatten()
x_test= x_test.flatten()

newpipeline2.fit(X_train,Y_train) #training the model

#testing accuracy

print('Training set score: ' + str(newpipeline2.score(X_train,Y_train)))
print('Test set score: ' + str(newpipeline2.score(x_test,y_test)))

#prediction
yhat=newpipeline2.predict(x_test)

#plotting matrix
cm=confusion_matrix(y_test, yhat)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

#printing scores
print(metrics.classification_report(y_test, yhat))

#pickle dumping
with open('svc_oversample.pickle', 'wb') as f:
    pickle.dump(newpipeline, f)
with open('svc_oversample.pickle', 'rb') as f:
    loadedpipe = pickle.load(f)
testing=loadedpipe.predict(["This is a good restaurant, but the service is average"])
testing[0]
test_df=pd.DataFrame(
    data={
        'text' : X_RUS.flatten(),
        'stars' : y_RUS
    }
)
test_df.shape
test_df.to_csv('undersampled_dataset.csv', index=False)

#model 3 random forestclassifier
newpipeline3 = Pipeline([('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()), 
    ('clf', RandomForestClassifier())])
X_train= X_train.flatten()
x_test= x_test.flatten()

newpipeline3.fit(X_train,Y_train) #training the model

#testing accuracy

print('Training set score: ' + str(newpipeline3.score(X_train,Y_train)))
print('Test set score: ' + str(newpipeline3.score(x_test,y_test)))

#prediction
yhat=newpipeline3.predict(x_test)

#plotting matrix
cm=confusion_matrix(y_test, yhat)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

#printing scores
print(metrics.classification_report(y_test, yhat))

#pickle dumping
with open('svc_oversample.pickle', 'wb') as f:
    pickle.dump(newpipeline, f)
with open('svc_oversample.pickle', 'rb') as f:
    loadedpipe = pickle.load(f)
testing=loadedpipe.predict(["This is a good restaurant, but the service is average"])
testing[0]
test_df=pd.DataFrame(
    data={
        'text' : X_RUS.flatten(),
        'stars' : y_RUS
    }
)
test_df.shape
test_df.to_csv('undersampled_dataset.csv', index=False)

#model 4 KNN
newpipeline4 = Pipeline([('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()), 
    ('clf', KNeighborsClassifier())])
X_train= X_train.flatten()
x_test= x_test.flatten()

newpipeline4.fit(X_train,Y_train) #training the model

#testing accuracy

print('Training set score: ' + str(newpipeline4.score(X_train,Y_train)))
print('Test set score: ' + str(newpipeline4.score(x_test,y_test)))

#prediction
yhat=newpipeline4.predict(x_test)

#plotting matrix
cm=confusion_matrix(y_test, yhat)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

#printing scores
print(metrics.classification_report(y_test, yhat))

#pickle dumping
with open('svc_oversample.pickle', 'wb') as f:
    pickle.dump(newpipeline4, f)
with open('svc_oversample.pickle', 'rb') as f:
    loadedpipe = pickle.load(f)
testing=loadedpipe.predict(["This is a good restaurant, but the service is average"])
print("star prediction: "+str(testing[0]))
test_df=pd.DataFrame(
    data={
        'text' : X_RUS.flatten(),
        'stars' : y_RUS
    }
)
test_df.shape
test_df.to_csv('undersampled_dataset.csv', index=False)

#model 5 adaboost
newpipeline5 = Pipeline([('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()), 
    ('clf', AdaBoostClassifier())])
X_train= X_train.flatten()
x_test= x_test.flatten()

newpipeline5.fit(X_train,Y_train) #training the model

#testing accuracy

print('Training set score: ' + str(newpipeline5.score(X_train,Y_train)))
print('Test set score: ' + str(newpipeline5.score(x_test,y_test)))

#prediction
yhat=newpipeline5.predict(x_test)

#plotting matrix
cm=confusion_matrix(y_test, yhat)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

#printing scores
print(metrics.classification_report(y_test, yhat))

#pickle dumping
with open('svc_oversample.pickle', 'wb') as f:
    pickle.dump(newpipeline5, f)
with open('svc_oversample.pickle', 'rb') as f:
    loadedpipe = pickle.load(f)
testing=loadedpipe.predict(["This is a good restaurant, but the service is average"])
print("star prediction: "+ str(testing[0]))
test_df=pd.DataFrame(
    data={
        'text' : X_RUS.flatten(),
        'stars' : y_RUS
    }
)
test_df.shape
test_df.to_csv('undersampled_dataset.csv', index=False)

f1_scores = [0.54, 0.37,0.51, 0.49, 0.37]
models = ['SVC', 'Decision Tree','Random Forest', 'Adaboost', 'KNN']
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.bar(models,f1_scores)
plt.show()