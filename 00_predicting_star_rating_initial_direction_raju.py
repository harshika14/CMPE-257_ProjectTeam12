# -*- coding: utf-8 -*-
"""00_Predicting_star_rating_initial_direction_Raju.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ER3c6WqGc3N5xVrkrvPS3z-Mchmi2NXA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

ca_restaurant_reviews=pd.read_csv("california_restaurants.csv")

ca_restaurant_reviews=ca_restaurant_reviews.reset_index(drop = True)

ca_restaurant_reviews.head(1)

import nltk
from nltk.corpus import stopwords
from tqdm import tqdm
from tqdm import tqdm_notebook

from collections import Counter

import string
def clean_text(sample_review):
    stopwords = nltk.corpus.stopwords.words('english')
    newStopWords = ['ive','hadnt','couldnt','didnt', 'id'] 
    stopwords.extend(newStopWords)
    text = sample_review

    text = text[2: len(sample_review)-1].lower()
    text = text.replace('\\n', ' ').replace('\\t', ' ')
    nopunc = [char for char in text if char not in string.punctuation]
    nopunc = ''.join(nopunc)

    
    l = [word for word in nopunc.split() if word.lower() not in stopwords]
    clean_text = ""
    for word in l:
        clean_text += str(word)+" "
    
    return clean_text.strip()

sample_review = ca_restaurant_reviews.text[20]
display(clean_text(sample_review))

import string
def get_words(text):

    stopwords = nltk.corpus.stopwords.words('english')
    newStopWords = ['ive','hadnt','couldnt','didnt', 'id'] 
    stopwords.extend(newStopWords)
    text = text[2: len(sample_review)-1].lower()  
    text = text.replace('\\n', ' ').replace('\\t', ' ')
    display(text)
    nopunc = [char for char in text if char not in string.punctuation]
    nopunc = ''.join(nopunc)
    
    display(nopunc)
    
    l = [word for word in nopunc.split() if word.lower() not in stopwords]
    
    return l, len(l)

for i in range(1):
    sample_review = str(ca_restaurant_reviews.text[i])
    check = get_words(sample_review)
    display(check[0])

pd.set_option('display.precision', 2)
ca_restaurant_reviews.describe()

print(ca_restaurant_reviews["review_stars"].value_counts())
type(ca_restaurant_reviews["review_stars"].value_counts())

labels = "5 stars","4 Stars", "3 Stars","1 Star","2 Stars"
sizes = ca_restaurant_reviews["review_stars"].value_counts()
colors = ['lightpink', 'yellowgreen', 'orange', 'lightskyblue','green']
 
# Plot
plt.pie(sizes, labels=labels,colors =colors, autopct='%1.1f%%') 
# plt.axis('equal')
plt.show()

from tqdm import tqdm

texts = []
stars = [ca_restaurant_reviews['review_stars'] for review in ca_restaurant_reviews]
pbar = tqdm(total=ca_restaurant_reviews.shape[0]+1)
for index, row in ca_restaurant_reviews.iterrows():
    texts.append(clean_text(row['text']))
    pbar.update(1)
pbar.close()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.feature_extraction.text import TfidfVectorizer
# vectorizer = TfidfVectorizer(ngram_range=(1,3))
# vectors = vectorizer.fit_transform(texts)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(vectors, stars[1], test_size=0.15, random_state=42, shuffle =False)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.svm import LinearSVC
# classifier = LinearSVC()
# 
# classifier.fit(X_train, y_train)

preds = classifier.predict(X_test)
print("Actual Ratings(Stars): ",end = "")
display(y_test[:5])
print("Predicted Ratings: ",end = "")
print(preds[:5])

X_null, X_full_test, y_null, y_full_test = train_test_split(vectors, stars[1], test_size=0.999995, random_state=42, shuffle = False)
predict_all = classifier.predict(X_full_test)

predicted_stars = list(predict_all)

print("Actual Ratings(Stars): ")
print(y_full_test[154730:154736])
print("\nPredicted Ratings: ",end = "")
print(predicted_stars[154730:154736])

ca_restaurant_reviews.shape

predicted_stars.append(3)

print("\nOriginal Reviews (with user bias)")
display(ca_restaurant_reviews.tail(10))

print("\nUnbiased Reviews (with predicted rating using user's review text)")
unbiased_reviews_dataset = ca_restaurant_reviews

# dropping actual ratings(stars) by user
#unbiased_reviews_dataset = unbiased_reviews_dataset.drop('review_stars', 1)

# adding the unbiased predicted rating
unbiased_reviews_dataset['predict'] = predicted_stars

display(unbiased_reviews_dataset.tail(10))

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, preds))

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
print ('Precision: ' + str(precision_score(y_test, preds, average='weighted')))
print ('Recall: ' + str(recall_score(y_test, preds, average='weighted')))

from sklearn.metrics import classification_report
print(classification_report(y_test, preds))

import itertools  
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

from sklearn import metrics
names = ['1','2','3','4','5']

# Compute confusion matrix
cnf_matrix = metrics.confusion_matrix(y_test, preds)
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=names,
                      title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=names, normalize=True,
                      title='Normalized confusion matrix')

plt.show()

sentiments = []
for star in stars[1]:
    if star <= 3:
        sentiments.append('n')
    if star > 3:
        sentiments.append('p')

print(len(sentiments))

X2_train, X2_test, y2_train, y2_test = train_test_split(vectors, sentiments, test_size=0.20, random_state=42)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# classifier2 = LinearSVC()
# classifier2.fit(X2_train, y2_train)

preds2 = classifier2.predict(X2_test)
print("Actual Class:    ",end = "")
print(y2_test[:10])
print("\nPredicted Class: ",end = "")
print(list(preds2[:10]))

print(accuracy_score(y2_test, preds2))

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
print ('Precision: ' + str(precision_score(y2_test, preds2, average='weighted')))
print ('Recall: ' + str(recall_score(y2_test, preds2, average='weighted')))

print(classification_report(y2_test, preds2))

print(metrics.confusion_matrix(y2_test, preds2))

class_names = ['negative','positive']

cnf_matrix = metrics.confusion_matrix(y2_test, preds2)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=class_names,
                      title='Confusion matrix, without normalization')

plt.figure()
plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,
                      title='Normalized confusion matrix')

plt.show()

